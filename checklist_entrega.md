# CHECKLIST E GUIA DE ENTREGA FINAL

**Projeto:** Sistema LLM para Responder Perguntas sobre SaÃºde PÃºblica  
**Disciplina:** Projeto e AnÃ¡lise de Algoritmos (PAA)  
**Data de Entrega:** 5 de novembro de 2025 (23:55)

---

## FASE 1: DOCUMENTAÃ‡ÃƒO E PLANEJAMENTO âœ“

### Documento TÃ©cnico (PDF ObrigatÃ³rio)

O documento PDF que serÃ¡ entregue deve conter:

#### SeÃ§Ã£o 1: Tema e Contexto (1 pÃ¡gina)
- [ ] Nome do tema: "QuestÃµes de SaÃºde PÃºblica com LLM"
- [ ] Justificativa: Por que escolheu este tema?
- [ ] Impacto potencial: Como ajuda a comunidade?
- [ ] RelevÃ¢ncia para PAA: Como envolve algoritmos eficientes?

#### SeÃ§Ã£o 2: Integrantes do Grupo (0.5 pÃ¡gina)
- [ ] Nome completo de cada integrante
- [ ] MatrÃ­cula de cada integrante
- [ ] Email de contato
- [ ] DivisÃ£o de responsabilidades

#### SeÃ§Ã£o 3: Linguagens Utilizadas (0.5 pÃ¡gina)
- [ ] **Backend:** Python 3.10+ (Linguagem principal)
- [ ] **Frontend:** HTML5, CSS3, JavaScript (ES6+)
- [ ] Justificativa de cada escolha

#### SeÃ§Ã£o 4: Stack TecnolÃ³gico (2 pÃ¡ginas)
Complete a tabela:

| Componente | Tecnologia | LicenÃ§a | PropÃ³sito |
|-----------|-----------|---------|----------|
| Framework ML | PyTorch 2.0+ | BSD | Treinamento deep learning |
| Biblioteca NLP | HF Transformers | Apache 2.0 | Modelos de linguagem |
| Fine-tuning | PEFT (LoRA) | Apache 2.0 | Treinamento eficiente |
| TokenizaÃ§Ã£o | HF Tokenizers | Apache 2.0 | Processamento de texto |
| Servidor | FastAPI | MIT | API REST backend |
| Servidor Web | Uvicorn | BSD | Servidor ASGI |
| Modelo Base | LLaMA 2 7B | Llama Community | Modelo prÃ©-treinado |
| Interface | HTML5/JS | MIT | ApresentaÃ§Ã£o frontend |
| Banco de Dados | SQLite3 | PD | PersistÃªncia (opcional) |

**Importante:** Todas as licenÃ§as DEVEM estar na lista aprovada!

#### SeÃ§Ã£o 5: Algoritmos e AnÃ¡lise de Complexidade (3-4 pÃ¡ginas)

Descrever cada algoritmo principal:

**5.1 TokenizaÃ§Ã£o (BPE)**
```
Algoritmo: Byte-Pair Encoding

Entrada: texto bruto
SaÃ­da: sequÃªncia de tokens

Complexidade: O(n Ã— log k)
EspaÃ§o: O(v)

Justificativa:
- n = caracteres do texto
- k = tamanho do vocabulÃ¡rio
- v = vocab final

Exemplo prÃ¡tico:
"Qual Ã© o perÃ­odo de incubaÃ§Ã£o?"
â†’ [1234, 5678, 9012, ...]
```

**5.2 Self-Attention (Transformer)**
```
Algoritmo: Multi-Head Self-Attention

FÃ³rmula: Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V

Complexidade por head: O(nÂ²)
EspaÃ§o: O(n Ã— d)

AnÃ¡lise:
- n = comprimento sequÃªncia
- d = dimensÃ£o do modelo
- Com h heads em paralelo: O(hÃ—nÂ²) â‰ˆ O(nÂ²)

Problema: QuadrÃ¡tico!
SoluÃ§Ã£o: Flash-Attention (reduz acesso memÃ³ria)

Exemplo numÃ©rico:
n=2048 (mÃ¡ximo tokens)
OperaÃ§Ãµes: 2048Â² = 4.194.304 por head
Com 8 heads: ~33M operaÃ§Ãµes
```

**5.3 Feed-Forward Network**
```
Algoritmo: MLP (Multilayer Perceptron)

Complexidade por exemplo: O(n Ã— dÂ²)
EspaÃ§o: O(dÂ²)

AnÃ¡lise:
d = 4096 (dimensÃ£o)
dÂ² = 16.777.216 parÃ¢metros

Com n tokens:
n Ã— dÂ² operaÃ§Ãµes por forward pass
```

**5.4 Fine-tuning com LoRA**
```
Algoritmo: Low-Rank Adaptation

Complexidade: O(E Ã— N Ã— r Ã— d)

ParÃ¢metros:
- E = nÃºmero de Ã©pocas (3)
- N = nÃºmero de exemplos (1250)
- r = rank LoRA (16)
- d = dimensÃ£o (4096)

Total: 3 Ã— 1250 Ã— 16 Ã— 4096 = 245M operaÃ§Ãµes
(vs 3 Ã— 1250 Ã— 7B sem LoRA)

ReduÃ§Ã£o: 99.7% menos computaÃ§Ã£o!
```

**5.5 InferÃªncia (GeraÃ§Ã£o)**
```
Algoritmo: GeraÃ§Ã£o Autoregressiva

Complexidade: O(m Ã— nÂ² Ã— d)

ParÃ¢metros:
- m = tokens gerados (atÃ© 512)
- n = contexto (atÃ© 2048)
- d = dimensÃ£o (4096)

AnÃ¡lise de tempo:
Cada token = 1 forward pass
512 tokens = 512 forward passes
Cada pass = ~1 segundo
Total = ~500 segundos no mÃ¡ximo
Com otimizaÃ§Ãµes: 3-5 segundos tÃ­pico
```

#### SeÃ§Ã£o 6: Metodologia de Treinamento (2 pÃ¡ginas)

**6.1 Dataset**
```
Fonte: [especificar suas fontes reais]
Tamanho: 1250 exemplos (75% train, 25% test)
DistribuiÃ§Ã£o: [descrever categorias]
Qualidade: [descrever processo de validaÃ§Ã£o]
```

**6.2 ConfiguraÃ§Ã£o de Fine-tuning**
```
Modelo Base: LLaMA 2 7B

ConfiguraÃ§Ã£o LoRA:
- rank: 16
- lora_alpha: 32
- dropout: 0.05
- target_modules: ["q_proj", "v_proj"]

ConfiguraÃ§Ã£o de Treinamento:
- num_epochs: 3
- batch_size: 4
- learning_rate: 2e-4
- warmup_steps: 100
- max_grad_norm: 1.0
```

**6.3 EstratÃ©gia de Treinamento**
```
Fase 1: PreparaÃ§Ã£o (semana 1)
- Coleta de dados
- AnÃ¡lise exploratÃ³ria
- PrÃ©-processamento

Fase 2: Desenvolvimento (semanas 2-4)
- ImplementaÃ§Ã£o backend
- Fine-tuning
- Primeiros testes

Fase 3: IntegraÃ§Ã£o (semanas 5-6)
- Interface web
- Testes fim-a-fim
- OtimizaÃ§Ãµes

Fase 4: AvaliaÃ§Ã£o (semana 7)
- MÃ©tricas finais
- DocumentaÃ§Ã£o
- ApresentaÃ§Ã£o
```

#### SeÃ§Ã£o 7: Arquitetura do Sistema (1-2 pÃ¡ginas)

Incluir diagrama (ASCII art ou imagem):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Interface Web     â”‚
â”‚  (HTML5/JavaScript) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server     â”‚
â”‚  (Backend Python)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Memory
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLaMA 2 + LoRA      â”‚
â”‚ (Modelo de IA)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Descrever fluxo de dados completo.

#### SeÃ§Ã£o 8: MÃ©tricas e AvaliaÃ§Ã£o (1 pÃ¡gina)

Como avaliarÃ¡ o sucesso:
```
1. MÃ©trica de Qualidade
   - BLEU Score
   - ROUGE Score
   - AcurÃ¡cia em teste set
   
2. MÃ©trica de Performance
   - Tempo mÃ©dio de resposta
   - Tempo de treinamento
   - Uso de memÃ³ria
   
3. MÃ©trica de Complexidade
   - AnÃ¡lise assintÃ³tica O(n)
   - AnÃ¡lise empÃ­rica com grÃ¡ficos
   - ComparaÃ§Ã£o esperado vs real
```

#### SeÃ§Ã£o 9: Cronograma (0.5 pÃ¡gina)

Tabela com:
- Semana
- Atividades
- ResponsÃ¡vel
- Status

#### SeÃ§Ã£o 10: ReferÃªncias (0.5 pÃ¡gina)

- Artigos cientÃ­ficos consultados
- DocumentaÃ§Ã£o oficial
- RepositÃ³rios GitHub
- Tutoriais seguidos

**Total esperado: 12-15 pÃ¡ginas de conteÃºdo tÃ©cnico**

---

## FASE 2: IMPLEMENTAÃ‡ÃƒO âœ“

### CÃ³digo EntregÃ¡vel

Estrutura de arquivos esperada:

```
PAA_SeuNome_Matricula.zip
â”œâ”€â”€ README.md (instruÃ§Ãµes para rodar)
â”œâ”€â”€ requirements.txt (dependÃªncias Python)
â”œâ”€â”€ Dataset/
â”‚   â”œâ”€â”€ dados_brutos/ (dados originais)
â”‚   â”œâ”€â”€ dados_processados.json (apÃ³s limpeza)
â”‚   â””â”€â”€ dataset_analise.py (script de anÃ¡lise)
â”œâ”€â”€ Coleta/
â”‚   â”œâ”€â”€ collect_data.py
â”‚   â””â”€â”€ dados.json
â”œâ”€â”€ Preprocessamento/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ tokenizer_utils.py
â”‚   â””â”€â”€ validation.py
â”œâ”€â”€ Treinamento/
â”‚   â”œâ”€â”€ fine_tuning.py
â”‚   â”œâ”€â”€ model_config.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ lora_config.json
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ main.py (FastAPI server)
â”‚   â”œâ”€â”€ endpoints.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css (opcional)
â”‚   â””â”€â”€ script.js
â”œâ”€â”€ AnÃ¡lise/
â”‚   â”œâ”€â”€ complexidade_analysis.py
â”‚   â”œâ”€â”€ metricas.py
â”‚   â””â”€â”€ graficos.py
â””â”€â”€ Documentacao/
    â”œâ”€â”€ ANALISE_COMPLEXIDADE.md
    â”œâ”€â”€ GUIA_USUARIO.md
    â”œâ”€â”€ DECISOES_TECNICAS.md
    â””â”€â”€ graficos/ (PNG/PDF dos grÃ¡ficos)

```

### CÃ³digo MÃ­nimo Funcional

- [ ] Script de coleta de dados (`collect_data.py`)
- [ ] Script de prÃ©-processamento (`preprocess.py`)
- [ ] Script de fine-tuning (`fine_tuning.py`)
- [ ] Backend FastAPI (`main.py`)
- [ ] Frontend HTML (`index.html`)
- [ ] Script de anÃ¡lise (`complexidade_analysis.py`)

### Testes e ValidaÃ§Ã£o

- [ ] Sistema roda sem erros
- [ ] Backend inicia na porta 8000
- [ ] Frontend carrega sem erros
- [ ] Pode fazer pergunta e receber resposta
- [ ] Interface Ã© usÃ¡vel e responsiva

---

## FASE 3: ANÃLISE DE COMPLEXIDADE âœ“

Este Ã© o DIFERENCIAL para PAA!

### O que Deve Conter

- [ ] **AnÃ¡lise TeÃ³rica (Big-O)**
  - TokenizaÃ§Ã£o: O(n Ã— log k)
  - Self-Attention: O(nÂ²)
  - Fine-tuning: O(E Ã— N Ã— r Ã— d)
  - InferÃªncia: O(m Ã— nÂ² Ã— d)

- [ ] **AnÃ¡lise EmpÃ­rica**
  - Medir tempo real de cada operaÃ§Ã£o
  - Tabela com n vs tempo
  - GrÃ¡ficos: linear, quadrÃ¡tico, exponencial
  - Comparar teÃ³rico vs prÃ¡tico

- [ ] **ComparaÃ§Ã£o: Com vs Sem LoRA**
  - Tabela lado-a-lado
  - MemÃ³ria: 84GB vs 4GB
  - Tempo: 450min vs 45min
  - Speedup: 10x

- [ ] **GrÃ¡ficos ObrigatÃ³rios**
  1. Loss durante treinamento
  2. Tempo de resposta vs tamanho de entrada
  3. MemÃ³ria utilizada
  4. ComparaÃ§Ã£o complexidade teÃ³rica

### Formato de AnÃ¡lise

Arquivo: `ANALISE_COMPLEXIDADE.md`

```markdown
# AnÃ¡lise de Complexidade

## 1. TokenizaÃ§Ã£o

### AnÃ¡lise TeÃ³rica
Complexidade: O(n Ã— log k)
Justificativa: ...

### AnÃ¡lise EmpÃ­rica
| n (tokens) | Tempo (ms) |
|-----------|-----------|
| 100       | 2.5       |
| 500       | 8.3       |
| 1000      | 15.2      |
| 2000      | 28.5      |

### GrÃ¡fico
[incluir grÃ¡fico]

### ConclusÃ£o
Comportamento observado: Linear
Matches teÃ³rico: Sim âœ“
```

---

## FASE 4: APRESENTAÃ‡ÃƒO âœ“

### Slides (20 minutos)

Estrutura recomendada:

1. **Capa** (1 slide)
   - TÃ­tulo do projeto
   - Nomes dos integrantes
   - Data

2. **Contexto** (2 slides)
   - O que Ã© saÃºde pÃºblica?
   - Por que LLM para este tema?
   - DemonstraÃ§Ã£o rÃ¡pida

3. **Dados** (2 slides)
   - Fonte dos dados
   - Quantidade e distribuiÃ§Ã£o
   - Exemplos de perguntas/respostas

4. **FundamentaÃ§Ã£o TeÃ³rica** (3 slides)
   - O que Ã© um Transformer?
   - Self-attention explicado
   - Arquitetura geral (diagrama)

5. **ImplementaÃ§Ã£o** (2 slides)
   - Stack tecnolÃ³gico (tabela)
   - Arquitetura do sistema (diagrama)

6. **Fine-tuning e LoRA** (2 slides)
   - Como funciona LoRA?
   - ComparaÃ§Ã£o: com vs sem LoRA
   - GrÃ¡fico de reduÃ§Ã£o de complexidade

7. **AnÃ¡lise de Complexidade** (3 slides)
   - AnÃ¡lise teÃ³rica de cada componente
   - GrÃ¡ficos de performance empÃ­rica
   - ConclusÃµes

8. **Resultados** (2 slides)
   - MÃ©tricas de qualidade
   - Tempo de resposta
   - Exemplos de perguntas/respostas bem-sucedidas

9. **DemonstraÃ§Ã£o** (demo ao vivo - nÃ£o em slide)
   - 4-5 perguntas diferentes
   - Mostrar tempo de processamento

10. **ConclusÃ£o** (1 slide)
    - Aprendizados principais
    - LimitaÃ§Ãµes encontradas
    - Melhorias futuras

### DemonstraÃ§Ã£o Ao Vivo

**Setup:**
```bash
# Terminal 1: Backend
source venv/bin/activate
python main.py

# Terminal 2: Frontend
# Abrir arquivo index.html no navegador
```

**Perguntas para Demonstrar:**
1. "Quais sÃ£o os sintomas da dengue?"
2. "Como prevenir COVID-19?"
3. "O que Ã© vacinaÃ§Ã£o?"
4. "Qual a diferenÃ§a entre vÃ­rus e bactÃ©ria?"
5. "Como funciona o sistema imunolÃ³gico?"

**MÃ©tricas a Mostrar:**
- Tempo de resposta de cada pergunta
- Qualidade das respostas
- Interface responsiva

---

## FASE 5: ENTREGA FINAL âœ“

### Arquivo a Enviar

**Nome:** `PAA_PrimeiroNome_Matricula_Proj.zip`

**ConteÃºdo obrigatÃ³rio:**
- [ ] Documento PDF com seÃ§Ãµes 1-10 (tÃ©cnico)
- [ ] CÃ³digo-fonte comentado
- [ ] README.md com instruÃ§Ãµes
- [ ] requirements.txt
- [ ] Dataset (ou script para baixar)
- [ ] AnÃ¡lise de complexidade (grÃ¡ficos)
- [ ] Slides da apresentaÃ§Ã£o (PDF)
- [ ] Arquivo de configuraÃ§Ã£o (se houver)

**ConteÃºdo opcional mas valioso:**
- [ ] Testes unitÃ¡rios
- [ ] Dockerfile
- [ ] Notebook Jupyter com anÃ¡lise
- [ ] VÃ­deo de demonstraÃ§Ã£o

### Checklist Final

#### DocumentaÃ§Ã£o
- [ ] PDF tÃ©cnico completo (12-15 pÃ¡ginas)
- [ ] Todas as seÃ§Ãµes preenchidas
- [ ] AnÃ¡lise de complexidade rigorosa
- [ ] ReferÃªncias adequadas
- [ ] Sem erros de portuguÃªs/formato

#### CÃ³digo
- [ ] Sem erros de sintaxe
- [ ] Bem comentado
- [ ] Segue boas prÃ¡ticas Python
- [ ] Modular e reutilizÃ¡vel
- [ ] Todos os requisitos instalÃ¡veis

#### Funcionalidade
- [ ] Sistema roda sem erros
- [ ] Pode fazer perguntas e receber respostas
- [ ] Interface Ã© amigÃ¡vel
- [ ] Tempo de resposta aceitÃ¡vel

#### ApresentaÃ§Ã£o
- [ ] Slides claros e profissionais
- [ ] DemonstraÃ§Ã£o testada e funcionando
- [ ] Todos entendem cada parte
- [ ] Tempo de apresentaÃ§Ã£o respeitado (20 min)
- [ ] AnÃ¡lise de complexidade explicada bem

#### Requisitos PAA
- [ ] AnÃ¡lise de complexidade O(n) teÃ³rica
- [ ] ValidaÃ§Ã£o empÃ­rica com dados reais
- [ ] GrÃ¡ficos comparativos
- [ ] JustificaÃ§Ã£o de decisÃµes algorÃ­tmicas
- [ ] DiscussÃ£o de trade-offs

---

## SCORING ESPERADO

Para obter nota mÃ¡xima:

| CritÃ©rio | Peso | Como Garantir |
|----------|------|---------------|
| DocumentaÃ§Ã£o TÃ©cnica | 20% | Completa, detalhada, sem erros |
| CÃ³digo Funcional | 20% | Sem bugs, bem estruturado |
| AnÃ¡lise de Complexidade | 25% | TeÃ³rica + empÃ­rica + grÃ¡ficos |
| ApresentaÃ§Ã£o | 20% | Clara, profissional, demonstraÃ§Ã£o |
| InovaÃ§Ã£o/Qualidade | 15% | Extras: otimizaÃ§Ãµes, testes, etc |

---

## DICAS FINAIS

### âœ… FaÃ§a
1. Comece cedo (nÃ£o deixe para Ãºltima semana)
2. Documente tudo enquanto escreve cÃ³digo
3. Teste frequentemente
4. Mantenha anÃ¡lise atualizada
5. Prepare apresentaÃ§Ã£o com antecedÃªncia
6. Teste demo ao vivo mÃºltiplas vezes

### âŒ Evite
1. CÃ³digo desorganizado/sem comentÃ¡rios
2. AnÃ¡lise de complexidade superficial
3. Deixar tudo para Ãºltima noite
4. Demo sem testes prÃ©vios
5. ApresentaÃ§Ã£o apressada
6. Tecnologias nÃ£o open-source

---

## CONTATO E SUPORTE

Se tiver dÃºvidas:

1. **Sobre o projeto:** Revise este documento
2. **Sobre cÃ³digo:** Consulte `guia_codigo_LLM.md`
3. **Sobre teoria:** Consulte `pesquisa_LLM_saude.md`
4. **Sobre arquitetura:** Consulte `arquitetura_diagramas.md`

---

## FÃ“RMULA DO SUCESSO

```
SUCESSO = Planejamento (20%)
        + ImplementaÃ§Ã£o (20%)
        + AnÃ¡lise tÃ©cnica (25%)
        + ApresentaÃ§Ã£o (20%)
        + Qualidade (15%)

NÃ£o pule nenhum desses passos!
```

---

**Boa sorte! VocÃªs conseguem! ğŸš€**

Data de Entrega: **5 de novembro de 2025 - 23:55**

