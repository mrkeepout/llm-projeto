# RESUMO EXECUTIVO: Projeto LLM para SaÃºde PÃºblica

**Data:** Novembro 2025  
**Disciplina:** Projeto e AnÃ¡lise de Algoritmos (PAA)  
**Universidade:** UnB - Departamento de CiÃªncia da ComputaÃ§Ã£o  

---

## ğŸ“‹ VISÃƒO GERAL

Seu grupo desenvolvarÃ¡ um **sistema de InteligÃªncia Artificial (LLM)** capaz de responder perguntas em linguagem natural sobre **SaÃºde PÃºblica**.

**O sistema funcionarÃ¡ assim:**

```
UsuÃ¡rio pergunta:
"O que Ã© dengue?"
        â†“
[Servidor Backend processa com IA]
        â†“
Sistema responde:
"Dengue Ã© uma doenÃ§a infecciosa..."
        â†“
Resposta exibida em interface web
```

---

## ğŸ¯ OBJETIVOS PRINCIPAIS

1. **Coletar dados** sobre saÃºde pÃºblica
2. **Treinar modelo LLM** com esses dados
3. **Criar interface web** para interaÃ§Ã£o
4. **Analisar complexidade** dos algoritmos
5. **Apresentar resultados** Ã  turma

---

## ğŸ› ï¸ TECNOLOGIA RECOMENDADA

| Componente | Tecnologia | Por QuÃª? |
|-----------|-----------|---------|
| **Linguagem** | Python | Melhor ecossistema para ML/NLP |
| **Framework ML** | PyTorch | FlexÃ­vel, moderno, padrÃ£o ouro |
| **Modelo Base** | LLaMA 2 7B | Open-source, bom custo/benefÃ­cio |
| **Fine-tuning** | LoRA | 95% menos memÃ³ria, 10x mais rÃ¡pido |
| **Backend** | FastAPI | RÃ¡pido, fÃ¡cil, PythÃ´nico |
| **Frontend** | HTML5 + JavaScript | Simples, nÃ£o requer build tools |

**Todas as tecnologias sÃ£o OPEN SOURCE com licenÃ§as apropriadas** âœ…

---

## ğŸ“Š STACK FINAL

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INTERFACE WEB                      â”‚
â”‚   (HTML5 + JavaScript)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FASTAPI (Python)                   â”‚
â”‚   - API REST                         â”‚
â”‚   - Processa perguntas              â”‚
â”‚   - Retorna respostas               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ GPU Memory
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLAMA 2 7B + LoRA                 â”‚
â”‚   - Modelo base prÃ©-treinado        â”‚
â”‚   - Adaptadores especializados      â”‚
â”‚   - Treinado em dados de SP         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¾ DADOS

### Fontes Recomendadas:
- **WHO** (OrganizaÃ§Ã£o Mundial de SaÃºde)
- **MedQA Dataset** (modificado)
- **PubMed Central** (artigos cientÃ­ficos)
- **Seu prÃ³prio dataset** (manualmente coletado)

### Requisitos:
- âœ… MÃ­nimo 500 exemplos
- âœ… MÃ¡ximo 10.000 exemplos
- âœ… Balanceado por categoria
- âœ… Revisado por qualidade

### Estrutura:
```json
{
  "pergunta": "O que Ã© dengue?",
  "resposta": "Dengue Ã© uma doenÃ§a infecciosa...",
  "categoria": "doenÃ§as_infecciosas",
  "confianÃ§a": 0.95
}
```

---

## ğŸ§  COMO FUNCIONA O TREINAMENTO

### Passo 1: Modelo PrÃ©-Treinado
```
LLaMA 2 7B (fornecido pela Meta)
â†“
JÃ¡ conhece padrÃµes gerais de linguagem
â†“
Mas nÃ£o sabe sobre saÃºde pÃºblica especificamente
```

### Passo 2: Fine-Tuning com LoRA
```
Seus dados de saÃºde pÃºblica
â†“
Passados pelo modelo durante treinamento
â†“
Modelo aprende a responder sobre seu tema
â†“
Apenas 0.2% dos parÃ¢metros sÃ£o atualizados (LoRA)
```

### Passo 3: Resultado
```
Modelo especializado em saÃºde pÃºblica
â†“
Pronto para responder perguntas
â†“
Em tempo real via interface web
```

---

## âš¡ ANÃLISE DE COMPLEXIDADE (PARA SEU RELATÃ“RIO)

### TokenizaÃ§Ã£o
```
Complexidade: O(n Ã— log k)
n = caracteres, k = vocab size
EspaÃ§o: O(v) = 50.000 tokens
```

### Self-Attention (Transformer)
```
Complexidade: O(nÂ²)
n = comprimento da sequÃªncia

Exemplo:
- 100 tokens â†’ 10.000 operaÃ§Ãµes
- 1.000 tokens â†’ 1.000.000 operaÃ§Ãµes
- 2.000 tokens â†’ 4.000.000 operaÃ§Ãµes
```

### Fine-Tuning
```
SEM LoRA:
ParÃ¢metros: 7 bilhÃµes
MemÃ³ria: 28 GB

COM LoRA:
ParÃ¢metros: 13 milhÃµes (0.2%)
MemÃ³ria: 262 KB
Speedup: 10x mais rÃ¡pido
```

### InferÃªncia (Responder Pergunta)
```
Complexidade: O(n Ã— dÂ²)
n = tokens gerados
d = dimensÃ£o do modelo

Tempo tÃ­pico: 3-5 segundos por resposta
Em GPU moderna: ~2-3 segundos
```

---

## ğŸ“… CRONOGRAMA SUGERIDO

| Semana | Atividades | Horas |
|--------|-----------|-------|
| 1 | Setup, requisitos, dataset | 15h |
| 2 | AnÃ¡lise de dados, prÃ©-processamento | 12h |
| 3 | ImplementaÃ§Ã£o backend | 20h |
| 4 | Fine-tuning do modelo | 15h |
| 5 | Frontend + integraÃ§Ã£o | 10h |
| 6 | Testes, documentaÃ§Ã£o, anÃ¡lise | 12h |
| 7 | PreparaÃ§Ã£o apresentaÃ§Ã£o | 10h |
| **Total** | | **94h** |

**Por pessoa:** 94h Ã· n_pessoas

---

## ğŸ¬ O QUE APRESENTAR Ã€ TURMA

### 1. Slides (20 minutos)
- âœ… Explicar o tema e por que usou IA
- âœ… Mostrar arquitetura do sistema
- âœ… Explicar Transformers (visualmente)
- âœ… AnÃ¡lise de complexidade com grÃ¡ficos
- âœ… Resultados e mÃ©tricas

### 2. DemonstraÃ§Ã£o Ao Vivo (10 minutos)
- âœ… Interface web funcionando
- âœ… 4-5 perguntas diferentes
- âœ… Mostrar tempo de resposta
- âœ… Exemplos de casos de sucesso

### 3. DiscussÃ£o TÃ©cnica (5 minutos)
- âœ… Desafios encontrados
- âœ… SoluÃ§Ãµes implementadas
- âœ… LimitaÃ§Ãµes do sistema

---

## ğŸ’¡ DICAS PARA O SUCESSO

### âœ… FaÃ§a:
1. **Use LoRA** - Reduz complexidade drasticamente
2. **Comece pequeno** - 500 exemplos Ã© suficiente para demo
3. **Documente tudo** - Cada decisÃ£o deve ser justificada
4. **Teste frequentemente** - NÃ£o espere terminar tudo
5. **Rastreie mÃ©tricas** - Mantenha grÃ¡ficos do progresso

### âŒ Evite:
1. âŒ Treinar modelo completo (28GB memÃ³ria necessÃ¡ria)
2. âŒ Usar dados nÃ£o verificados (qualidade importante)
3. âŒ Descuidar da anÃ¡lise de complexidade (requisito PAA)
4. âŒ Deixar tudo para Ãºltima semana
5. âŒ Tentar GPT-4 (nÃ£o Ã© open-source, violaria requisito)

---

## ğŸš€ PRÃ“XIMOS PASSOS

### Imediato (esta semana):
1. âœ… Ler este documento completamente
2. âœ… Revisar arquivo `pesquisa_LLM_saude.md` com detalhes teÃ³ricos
3. âœ… Revisar arquivo `guia_codigo_LLM.md` com exemplos prÃ¡ticos
4. âœ… Reunir-se com seu grupo
5. âœ… ComeÃ§ar setup do ambiente Python

### Curto prazo (prÃ³ximas 2 semanas):
1. Definir e coletar dataset
2. Implementar scripts de prÃ©-processamento
3. Familiarizar-se com PyTorch e Transformers
4. Fazer primeiro treinamento teste

### MÃ©dio prazo (semanas 3-5):
1. Refinar dataset e modelo
2. Desenvolver backend FastAPI
3. Criar interface web
4. Testes e ajustes

### Longo prazo (semanas 6-7):
1. OtimizaÃ§Ãµes finais
2. DocumentaÃ§Ã£o completa
3. PreparaÃ§Ã£o de apresentaÃ§Ã£o
4. AnÃ¡lise de complexidade final

---

## ğŸ“š ARQUIVOS DE SUPORTE

VocÃª recebeu **3 documentos**:

1. **pesquisa_LLM_saude.md** (15 pÃ¡ginas)
   - FundamentaÃ§Ã£o teÃ³rica completa
   - ExplicaÃ§Ã£o de Transformers e LLMs
   - Metodologias de fine-tuning
   - AnÃ¡lise detalhada de complexidade
   - ReferÃªncias bibliogrÃ¡ficas

2. **guia_codigo_LLM.md** (10 pÃ¡ginas)
   - CÃ³digo Python pronto para usar
   - Scripts de coleta de dados
   - ImplementaÃ§Ã£o de fine-tuning
   - Backend FastAPI completo
   - Interface web HTML/JS

3. **resumo_executivo.md** (este arquivo)
   - VisÃ£o geral do projeto
   - Guia rÃ¡pido de referÃªncia
   - Cronograma e prÃ³ximos passos

---

## ğŸ“ VALOR EDUCACIONAL

Este projeto ensina:

- ğŸ§  **Processamento de Linguagem Natural** (NLP)
- ğŸ”¬ **Deep Learning** com Transformers
- âš¡ **OtimizaÃ§Ã£o de Algoritmos** (LoRA, quantizaÃ§Ã£o)
- ğŸ—ï¸ **Arquitetura de Sistemas** (backend, frontend)
- ğŸ“Š **AnÃ¡lise de Complexidade** (O-grande, empiricamente)
- ğŸ”§ **Engenharia de ML** (dados, treino, deployment)
- ğŸ’» **Full-stack Development** (Python, JavaScript, Web)

---

## ğŸ¤ DISTRIBUIÃ‡ÃƒO DE TRABALHO (SugestÃ£o)

Para grupo de **4 pessoas**:

**Pessoa 1 - Data & Backend:**
- Coleta e prÃ©-processamento de dados
- ImplementaÃ§Ã£o FastAPI

**Pessoa 2 - ML & Training:**
- Setup de ambiente ML
- Fine-tuning do modelo
- AnÃ¡lise de complexidade

**Pessoa 3 - Frontend & UI:**
- Interface HTML/JavaScript
- IntegraÃ§Ã£o com backend
- Testes de usabilidade

**Pessoa 4 - DocumentaÃ§Ã£o & ApresentaÃ§Ã£o:**
- Escrever relatÃ³rio tÃ©cnico
- Criar slides
- Preparar demonstraÃ§Ã£o

---

## â“ PERGUNTAS FREQUENTES

**P: Preciso de GPU?**  
R: LoRA funciona em GPUs com 6-8GB (vocÃª provavelmente tem isso)

**P: Posso usar meu laptop?**  
R: Sim, mas vai ser mais lento. GPU recomendada, CPU funciona tambÃ©m

**P: E se nÃ£o tiver GPU?**  
R: Use Google Colab (grÃ¡tis, com GPU T4)

**P: Quanto tempo de treinamento?**  
R: ~45 min em V100, ~2h em GPU modesta, ~6h em CPU

**P: Preciso de muitos dados?**  
R: NÃ£o! 500 exemplos jÃ¡ Ã© suficiente para demo

**P: Como garanto qualidade das respostas?**  
R: Dataset de qualidade + ajuste de temperatura + validaÃ§Ã£o

---

## ğŸ“ SUPORTE TÃ‰CNICO

Se encontrar problemas:

1. **Erro ao instalar PyTorch:** Visite pytorch.org para instruÃ§Ãµes GPU/CPU especÃ­ficas
2. **Modelo nÃ£o carrega:** Verificar espaÃ§o em disco (7B = ~13GB)
3. **FastAPI nÃ£o funciona:** `pip install python-dotenv` e verificar porta 8000
4. **Resposta muito genÃ©rica:** Aumentar epochs ou melhorar dataset

---

## ğŸ† OBJETIVO FINAL

Ao terminar este projeto, vocÃª terÃ¡:

âœ… Um **sistema de IA funcionando**  
âœ… **ApresentaÃ§Ã£o tÃ©cnica** impressionante  
âœ… **CompreensÃ£o profunda** de LLMs e NLP  
âœ… **CÃ³digo bem documentado** e reutilizÃ¡vel  
âœ… **AnÃ¡lise rigorosa** de complexidade algorÃ­tmica  
âœ… **PrÃ¡tica em full-stack development**  
âœ… **PortfÃ³lio impressionante** para carreira  

---

## ğŸ“ CHECKLIST FINAL

Antes de apresentar, verifique:

- [ ] CÃ³digo estÃ¡ limpo e comentado
- [ ] AnÃ¡lise de complexidade estÃ¡ correta e justificada
- [ ] Sistema funciona sem erros (demo testada)
- [ ] Dados sÃ£o de fonte confiÃ¡vel
- [ ] RelatÃ³rio tÃ©cnico Ã© completo
- [ ] Slides sÃ£o claros e visualmente interessantes
- [ ] Todos os integrantes entendem cada parte
- [ ] LicenÃ§as open-source estÃ£o verificadas
- [ ] Cronograma foi respeitado
- [ ] Qualidade de apresentaÃ§Ã£o Ã© profissional

---

**Boa sorte! VocÃªs conseguem! ğŸš€**

*Qualquer dÃºvida especÃ­fica, consulte os documentos de pesquisa e cÃ³digo fornecidos.*

